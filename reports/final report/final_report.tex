\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{url}
\usepackage{geometry}
\geometry{a4paper,scale=0.7}

\usepackage{subfigure}
\usepackage{subfloat}
\def\UrlBreaks{\do\A\do\B\do\C\do\D\do\E\do\F\do\G\do\H\do\I\do\J
\do\K\do\L\do\M\do\N\do\O\do\P\do\Q\do\R\do\S\do\T\do\U\do\V
\do\W\do\X\do\Y\do\Z\do\[\do\\\do\]\do\^\do\_\do\`\do\a\do\b
\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j\do\k\do\l\do\m\do\n
\do\o\do\p\do\q\do\r\do\s\do\t\do\u\do\v\do\w\do\x\do\y\do\z
\do\.\do\@\do\\\do\/\do\!\do\_\do\|\do\;\do\>\do\]\do\)\do\,
\do\?\do\'\do+\do\=\do\#} 

\title{News Popularity Prediction on Facebook}
\author{\\Yue Zhuang\\
Brown University DSI\\
Git:\url{https://github.com/zysophia/News_Rank_Prediction}\\\\}
\date{}

\usepackage{natbib}
\usepackage{graphicx}
\graphicspath{{../../figures/}}
\setlength{\parskip}{0.3\baselineskip}
\usepackage{indentfirst}

\begin{document}

\maketitle

\section{Introduction}
In this section, we will give a brief description of the problem and the dataset we would work on.
\subsection{Problem Description}
In this project, we would like to dig into the popularity of news on the Facebook News platform. With the timing of publishment an important feature that affects the popularity of news, we will develop a real time predicting system for the popularity of certain piece of news.\par
The target variable of our project would be the popularity rate in the near future (20 minutes) of a certain piece of news.\par
The problem is regression since we will predict the popularity rate of news, which is a continuous variable.\par
The prediction of popularity rate of news can be of significant importance for the recommend systems. Social media platforms will be able to push the most popular piece of news to consumers by introducing the real-time prediction model to their existing recommend system.

\subsection{Dataset Description}
\subsubsection{Data Source}
Our data comes from the UCI dataset:
\url{https://archive.ics.uci.edu/ml/datasets/News+Popularity+in+Multiple+Social+Media+Platforms}
\subsubsection{Dataset Structures}
In this section, we will describe the dataset â€“ News Popularity in Multiple Social Media Platforms Data Set. This is a large data set of news items and their respective social feedback on multiple platforms. The collected data relates to a period of 8 months, between November 2015 and July 2016, accounting for about 100,000 news items on four different topics: economy, microsoft, obama and palestine.

\begin{itemize}
\item \textbf{news final sheet}
In this csv file, each row represents a certain piece of news, with total 93240 rows.\par
The columns includes 11 features: its IDLink, title, headline, source, topic, publishdate, sentimenttitle, sentimentheadline and the final popularity on different social media platforms.
\item \textbf{times series sheet}
In these csv files, each file includes data for the time series popularity rate for news on a certain social media platform and with certain topics.  

\end{itemize}

\section{EDA}
In this section, we will perform some exploratory data analysis and show the results that we found the most informative for our model. We will go through three important findings during EDA.

\subsection{Popularity v.s. Topics}
 
\begin{figure}[H]
\centering
\includegraphics[scale=0.17]{"count of news by publish time"}
\caption{Count of news by publish time}
\end{figure}

The above figure shows a barplot of the number of news published on Facebook during November 2015 and July 2016, grouped by its respective topic. The data seems quite balanced here.

\begin{figure}[H]
\centering
\includegraphics[scale=0.17]{"count of news with popularity larger than 100 by publish time"}
\caption{Count of popular news by publish time}
\end{figure}

The above figure shows the same barplot but focuses on only those news with a total popularity rate greater than 100. We may find out from the plot that topics related with Obama is quite popular during 2015 and 2016, which indicates that we are having an unbalanced data set.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"box plot for popularity of hot news"}
\caption{Box plot for popularity of hot news}
\end{figure}

The boxplot above shows similar results about the unbalance characteristic of our dataset.

 
\subsection{Popularity Trend}

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{"violin plot of popularity rate"}
\caption{Violin plot of popularity rate}
\end{figure}

The violin plot gives the trend of popularity rate ratio for each piece of news during the first two days after its publishment. We could observe that the piece of news reaches an average 30\% of its total popularity in the first 20 minutes after publishment, consistent with the intuition that the news is most popular when it is first published while quickly lose popularity as time goes on.

\begin{figure}[H]
    \centering
    \subfigure[]{\includegraphics[width=0.45\textwidth]{"Facebook_Economy violin plot of popularity "}}
    \subfigure[]{\includegraphics[width=0.45\textwidth]{"Facebook_Obama violin plot of popularity rate"}} 
    \subfigure[]{\includegraphics[width=0.45\textwidth]{"Facebook_Microsoft violin plot of popularity "}}
    \subfigure[]{\includegraphics[width=0.45\textwidth]{"Facebook_Palestine violin plot of popularity "}}
    \caption{Violin Plot of Popularity Trend By Topics}
\end{figure}

The violin plots above shows the popularity trend for news with different topics. We could observe that the popularity trend of news is indeed closely related to its respective topic, where the plotting of Economy and Microsoft is bimodal while that of Obama and Palestine is quite smooth.


\subsection{News Popularity V.S. Topic Popularity}

\begin{figure}[H]
\centering
\includegraphics[scale=0.45]{"popu distrib 20m"}
\caption{Violin plot of popularity rate}
\end{figure}

The figure above shows a histogram of the density distribution of the popularity of news grouped by lower/ higher past (within 20 minutes) topic popularity. We can observe that when the corresponding topic is not popular, the news is very likely to be unpopular. However, the most popular news always appears where the topic is not popular. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"Popularity distrib 1h"}
\caption{Violin plot of popularity rate}
\end{figure}

To dig into the embedding reasoning for the scenario, we looked back into a longer period (1 hour) to check. The figure above shows that when we look back into a longer period, the most popular news still lies where the topic is not popular, but the news is not necessarily likely to be unpopular when the topic is not popular. We may make a bold conjecture that facebook is holding an imperfect recommendation system, and the news has not yet been exposed to users when the topic is not hot enough. 

\section{Methods}
In this section, we will go through the process of data preprocessing and give an overall description of the ML methods we performed as well as the parameter selection.
\subsection{Data Preprocessing}
In this section, we will go through the data preprocessing part.
\subsubsection{Missing Data}
Before merging the five raw dataframes we have, we would like to check the missing values. We have a missing rate of approximately 0.3\% and the MCAR test gives a result of 1.0. Thus we could just drop those rows with missing values.
\subsubsection{Basic Calculation}
To get more informative features for the model, we conducted some basic calculations for the change rate of popularity and the corresponding topic popularity, and then merge the dataframes.\par
The resulting dataframe has 37 columns.

\subsubsection{Encoder and Scaler}

\begin{itemize}
\item \textbf{One Hot Encoder: }
We applied the one hot encoder on the categorical data, topics.
\item \textbf{MinMax Scaler: }
We applied minmax scalers on all the continuous features excluding the sentiment value which is already normalized.
\item \textbf{Logarithm: }
We applied logarithm on the continuous features before scaling since we have extreme values.

\end{itemize}

\subsubsection{Final DataFrame}
The merged dataframe is a 121049 * 40 matrix, having 40 columns including 39 features and 1 target variable.\par
Additionally, as is mentioned by Nuno Moniz and Luis Torgo [2], when making predictions, we shall actually focus more on those data with a higher popularity rate. Thus, we have selected those rows with a target popularity greater than e05 for our model. The final dataframe is a 3412 * 40 matrix.

\subsection{ML Methods Overview}
\subsubsection{ML models and parameters}
We will first split the data into training (80\%) and testing (20\%), and then we will use kfold to conduct grid search for the best parameters. We have set the number of folds to be 5 here. Also, we have randomly set the random states for train\_test splitting for 5 times, going from 42 to 210 stepped by 42. We will measure the uncertainty caused by data splitting later.
\subsubsection{Evaluation Metrics}
We will use mean square error on the cross validation data to search for the best parameters since we are dealing with a regression problem. And then we calculate both the mean square error and the R square score on the test data to better evaluate the model outcome.

\subsection{Random Forest Regressor}

\subsubsection{Random Forest Regressor Parameters}
\begin{itemize}
\item \textbf{Max\_depth:}
Each integer in the range [6,10].
\item \textbf{Min\_samples\_split:}
Min\_samples\_split: In [0.025, 0.05, 0.1, 0.2].
\end{itemize}

\subsubsection{Random Forest Regressor Uncertainty}
To eliminate the bias caused by the selection of random state of the random forest model, we conducted an inner loop through the random\_state in [42, 84, 126], and then take the average as the outcome of the model. \par
To calculate the uncertainty due to the setting of random state, after we have selected the best parameters, we shall go through 10 random states to calculate the standard deviation of MSE and R2 score.


\subsection{Gradient Boosting Regressor}

\subsubsection{Gradient Boosting Regressor Parameters}
\begin{itemize}
\item \textbf{Max\_depth:}
Each integer in the range [3,8].
\item \textbf{Min\_samples\_split:}
Min\_samples\_split: In [0.025, 0.05, 0.1, 0.2].
\end{itemize}

\subsubsection{Gradient Boosting Regressor Uncertainty}
The procedure is the same as that of random forest regressor.

\subsection{SVR}

\subsubsection{SVR Parameters}
\begin{itemize}
\item \textbf{C:}
In [1, 10, 100, 1000].
\item \textbf{gamma:}
In [0.01, 0.1, 1.0, 10.0].
\end{itemize}


\section{Results}
\subsection{Baseline Scores}
We calculate the R2 score of the models to compare with baseline models.
\subsection{Parameters, Scores and Feature Importances}
In this section, we will discuss the best parameters of the models, the scores and feature importances.
\subsubsection{Random Forest Regressor}

\begin{itemize}
\item \textbf{Parameter selection}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{"rforest_param"}
\caption{RF Parameter GridSearch}
\end{figure}

The figure above shows the performance of the random forest model under multiple random splitting. We may observe that a max\_depth of 10 and a min\_samples\_split of 0.025 is pretty reasonable for the model. 
\item \textbf{Uncertainty by splitting}\\
We have an average MSE of 0.36 (with standard deviation 0.02) and an average R2 score of 0.46 (with standard deviation 0.02). The uncertainty comes from data splitting.
\item \textbf{Uncertainty by random state}\\
Fix the parameters to be the best ones (max\_depth = 10, min\_samples\_split = 0.025). And then run the model 5 times to estimate the uncertainty by random state of the random forest model. 
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"rf_rs_unc"}
\caption{RF Random State Uncertainty}
\end{figure}
The uncertainty caused by the random state of the model is actually pretty low.
\item \textbf{Feature importances}
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"rf_perm_imp"}
\caption{RF Permutation Feature Importances}
\end{figure}
The figure above shows the permutaion importances for the most important features among all. We could observe that the popularity history and publish time of the news is important for prediction.
\end{itemize}



\subsubsection{Gradient Boosting Regressor}

\begin{itemize}
\item \textbf{Parameter selection}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{"gbr_param"}
\caption{GBR Parameter GridSearch}
\end{figure}

We may observe that a max\_depth of 6 and a min\_samples\_split of 0.1 is pretty reasonable for the model. 
\item \textbf{Uncertainty by splitting}\\
We have an average MSE of 0.37 (with standard deviation 0.02) and an average R2 score of 0.45 (with standard deviation 0.02). 

\item \textbf{Uncertainty by random state}\\
Fix the parameters to be the best ones (max\_depth = 6, min\_samples\_split = 0.1). And then run the model 5 times to estimate the uncertainty by random state of the gradient boosting model. 
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"gbr_rs_unc"}
\caption{GBR Random State Uncertainty}
\end{figure}
The uncertainty caused by the random state of the model is actually pretty low.
\item \textbf{Feature importances}
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"gbr_perm_imp"}
\caption{GBR Permutation Feature Importances}
\end{figure}
The figure above shows the permutaion importances for the most important features among all. We could observe that the popularity history, topic polularity and publish time of the news is important for prediction.
\end{itemize}



\subsubsection{SVR}

\begin{itemize}
\item \textbf{Parameter selection}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{"svr_param"}
\caption{SVR Parameter GridSearch}
\end{figure}
We may observe that a C of 10 and a gamma of 0.1 is pretty reasonable for the model. 
\item \textbf{Uncertainty by splitting}\\
We have an average MSE of 0.4 (with standard deviation 0.03) and an average R2 score of 0.41 (with standard deviation 0.03). The uncertainty comes from data splitting.
\item \textbf{Feature importances}
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{"svr_perm_imp"}
\caption{SVR Permutation Feature Importances}
\end{figure}
The figure above shows the permutaion importances for the most important features among all. We could observe that the popularity history, publish time and topic of the news is important for prediction.
\end{itemize}


\subsection{Model Comparison}
The outcome of the random forest model is the best of the three, with lower MSE and higher R2 score.
\subsection{Business Interpretation}

As is shown in the model outcomes, we could obtain a reasonably low MSE with a comparatively high R2 score performing either the ensenble models or the svr model. The random forest regressor has the best performance amang all three.\par
The uncertainty of the prediction caused by either data splitting or non-deterministic models is comparatively low, indicating that we will be able to get a stable prediction performance.\par
The permutation importances of features appears to be different under three models. However, by observing the three feature importance measures, we could draw the conclusion that the future popularity rate of a piece of news is closely related to its popularity history and publish time. The topic popularity and the corresponding topic itself as well contribute to the prediction. This observation agrees with our intuition when dealing with news popularity.

\section{Outlook}

The model gives a reasonable outcome but there is still space for improvement.\par
Our model has 36 features, while a lot of them are closely correlated with each other. To maintain the interpretability of the model, we did not perform dimension reduction in our project. We may try to reduce some columns so as to improve the efficiency of training.\par
The sentiment features appear to be less informative in our prediction, which is unexpected. We may have perform some pre-calculation for the sentiment features to detect people's attitude toward a topic under certain periods. We may also collect data for the author of the news as extra features.\par
The tree based model performs better in our predictions than the support vector one, we may try other methods like neural network to see if it can get even better.

\medskip
\bibliographystyle{unsrt}
\begin{thebibliography}{}
\bibitem{ref1} 
 Nuno Moniz, Luis Torgo.
\textit{Multi Source Social Feedback of Online News Feeds}. 
 2018
 
\bibitem{ref2} 
 Nuno Moniz, Luis Torgo.
\textit{The Utility Problem of Web Content Popularity Prediction}.
 2018

\bibitem{ref3} 
Friedman, J. H. 
\textit{Greedy Function Approximation: A Gradient Boosting Machine}.
 1999

\bibitem{ref4} 
Cortes, Corinna, Vapnik, Vladimir N.
\textit{Support-vector networks}.
 1995

\bibitem{ref5} 
Ho, Tin Kam.
\textit{Random Decision Forests}.
 1995
\end{thebibliography}

\end{document}
